{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0QKqDn37vrv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx1IcEfzSWyq",
        "outputId": "581deadd-86c6-43af-8097-a8313051625c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTNld-yoq0pL",
        "outputId": "f30778b4-2870-4a0f-fef7-4c4faa596084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface_hub, datasets\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface_hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.4)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers huggingface_hub\n",
        "!apt-get install git-lfs\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install spacy\n",
        "!pip install gensim\n",
        "!pip install xgboost\n",
        "!pip install numpy scikit-learn\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!pip install sacremoses\n",
        "!pip install transformers torch sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgTqPhXzrYoJ",
        "outputId": "fb73decf-6279-4a80-9022-d860902db44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import string\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from datasets import Dataset,load_metric\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import wordnet_ic\n",
        "from nltk.corpus import wordnet\n",
        "from textblob import TextBlob\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, DataCollatorWithPadding, FlaubertTokenizer, FlaubertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('french'))\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw')\n",
        "nltk.download('wordnet_ic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W-rcFuur2vW"
      },
      "outputs": [],
      "source": [
        "# Import files\n",
        "sample_submission = pd.read_csv(\"https://raw.githubusercontent.com/allobo49/SBB/main/Data/sample_submission.csv\")\n",
        "training_data = pd.read_csv(\"https://raw.githubusercontent.com/allobo49/SBB/main/Data/training_data.csv\")\n",
        "unlabelled_test_data = pd.read_csv(\"https://raw.githubusercontent.com/allobo49/SBB/main/Data/unlabelled_test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CnsNWGzJ61aU",
        "outputId": "7b04c38c-9825-41a6-859f-f796eb3bc2e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id difficulty\n",
              "0        0         A1\n",
              "1        1         A1\n",
              "2        2         A1\n",
              "3        3         A1\n",
              "4        4         A1\n",
              "...    ...        ...\n",
              "1195  1195         A1\n",
              "1196  1196         A1\n",
              "1197  1197         A1\n",
              "1198  1198         A1\n",
              "1199  1199         A1\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fc43173-c34a-4f75-bb90-182e312c906d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fc43173-c34a-4f75-bb90-182e312c906d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fc43173-c34a-4f75-bb90-182e312c906d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fc43173-c34a-4f75-bb90-182e312c906d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67168d2f-6b4d-4b3c-a705-dd7a9df91b9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67168d2f-6b4d-4b3c-a705-dd7a9df91b9b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67168d2f-6b4d-4b3c-a705-dd7a9df91b9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample_submission",
              "summary": "{\n  \"name\": \"sample_submission\",\n  \"rows\": 1200,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 346,\n        \"min\": 0,\n        \"max\": 1199,\n        \"num_unique_values\": 1200,\n        \"samples\": [\n          1178,\n          865,\n          101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Read sample_submission\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mTo4x8yC7gdQ",
        "outputId": "ced154fe-e635-4c0b-93e1-68da75cc8a0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence difficulty\n",
              "0        0  Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1        1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2        2  Le test de niveau en français est sur le site ...         A1\n",
              "3        3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4        4  Dans les écoles de commerce, dans les couloirs...         B1\n",
              "...    ...                                                ...        ...\n",
              "4795  4795  C'est pourquoi, il décida de remplacer les hab...         B2\n",
              "4796  4796  Il avait une de ces pâleurs splendides qui don...         C1\n",
              "4797  4797  Et le premier samedi de chaque mois, venez ren...         A2\n",
              "4798  4798  Les coûts liés à la journalisation n'étant pas...         C2\n",
              "4799  4799  Sur le sable, la mer haletait de toute la resp...         C2\n",
              "\n",
              "[4800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ec61dbc-1908-41a3-92d4-2249ca8b4fc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>4795</td>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>4796</td>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>4797</td>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>4798</td>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>4799</td>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ec61dbc-1908-41a3-92d4-2249ca8b4fc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ec61dbc-1908-41a3-92d4-2249ca8b4fc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ec61dbc-1908-41a3-92d4-2249ca8b4fc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47b2b08e-f920-42e6-ac96-22d9c656a7df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47b2b08e-f920-42e6-ac96-22d9c656a7df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47b2b08e-f920-42e6-ac96-22d9c656a7df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data",
              "summary": "{\n  \"name\": \"training_data\",\n  \"rows\": 4800,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1385,\n        \"min\": 0,\n        \"max\": 4799,\n        \"num_unique_values\": 4800,\n        \"samples\": [\n          596,\n          3370,\n          3048\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4800,\n        \"samples\": [\n          \"Je peux m'asseoir ici ?\",\n          \"C'est la couleur de nombreux fruits et l\\u00e9gumes, comme les tomates, les fraises ou les cerises.\",\n          \"Pas au point qu'il faille en limiter la consommation, mais tout de m\\u00eame. D'autres \\u00e9diteurs exploitent le cr\\u00e9neau, et Internet regorge de sites int\\u00e9ressants qui permettent une approche moins scolaire, certes, mais tellement plus amusante, des math\\u00e9matiques.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"C1\",\n          \"A1\",\n          \"C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Read training_data\n",
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sZDJsfmU7mzs",
        "outputId": "09f1053e-3206-4ddd-a9aa-79db39542444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence\n",
              "0        0  Nous dûmes nous excuser des propos que nous eû...\n",
              "1        1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2        2  Et, paradoxalement, boire froid n'est pas la b...\n",
              "3        3  Ce n'est pas étonnant, car c'est une saison my...\n",
              "4        4  Le corps de Golo lui-même, d'une essence aussi...\n",
              "...    ...                                                ...\n",
              "1195  1195  C'est un phénomène qui trouve une accélération...\n",
              "1196  1196  Je vais parler au serveur et voir si on peut d...\n",
              "1197  1197  Il n'était pas comme tant de gens qui par pare...\n",
              "1198  1198      Ils deviennent dangereux pour notre économie.\n",
              "1199  1199  Son succès a généré beaucoup de réactions néga...\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f0a8a12-0a48-4b9b-8ccf-0c0bc5a4c5ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>C'est un phénomène qui trouve une accélération...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>Je vais parler au serveur et voir si on peut d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>Il n'était pas comme tant de gens qui par pare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>Ils deviennent dangereux pour notre économie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>Son succès a généré beaucoup de réactions néga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f0a8a12-0a48-4b9b-8ccf-0c0bc5a4c5ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f0a8a12-0a48-4b9b-8ccf-0c0bc5a4c5ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f0a8a12-0a48-4b9b-8ccf-0c0bc5a4c5ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f55db64f-b10f-48cc-abbb-34fadf2a215e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f55db64f-b10f-48cc-abbb-34fadf2a215e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f55db64f-b10f-48cc-abbb-34fadf2a215e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unlabelled_test_data",
              "summary": "{\n  \"name\": \"unlabelled_test_data\",\n  \"rows\": 1200,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 346,\n        \"min\": 0,\n        \"max\": 1199,\n        \"num_unique_values\": 1200,\n        \"samples\": [\n          1178,\n          865,\n          101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1200,\n        \"samples\": [\n          \"C'est mon restaurant pr\\u00e9f\\u00e9r\\u00e9, j'y suis all\\u00e9 deux fois cette semaine!\",\n          \"Avec leur directrice, Patricia Rodriguez, les \\u00e9l\\u00e8ves de la grande section de maternelle ne se lassent pas de ce spectacle\",\n          \"Pour y rem\\u00e9dier, \\u00e0 leur \\u00e9chelle, des militants ont commenc\\u00e9 \\u00e0 organiser leurs propres fili\\u00e8res d'importation d\\u00e8s la fin des ann\\u00e9es 1960.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Read unlabelled_test_data\n",
        "unlabelled_test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzS0lWiB71B1"
      },
      "source": [
        "# Data Augmentation and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aajD6DTRuxhE"
      },
      "outputs": [],
      "source": [
        "# Function to count words in each sentence excluding stop words\n",
        "def count_words(sentence):\n",
        "    # Tokenize the sentence\n",
        "    words = sentence.split()\n",
        "    # Return the count of non-stop words\n",
        "    return len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQNtzafqGxDO"
      },
      "outputs": [],
      "source": [
        "# Function to add a dot at the end of the sentence if it doesn't end with a punctuation mark\n",
        "def add_dot(sentence):\n",
        "    if sentence[-1] not in string.punctuation:\n",
        "        return sentence + '.'\n",
        "    else:\n",
        "        return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVBVZ60iAJsJ"
      },
      "outputs": [],
      "source": [
        "# Function to calculate average word length in a sentence\n",
        "def avg_word_length(sentence):\n",
        "    words = sentence.split()\n",
        "    word_lengths = [len(word) for word in words]\n",
        "    if len(word_lengths) == 0:\n",
        "        return 0\n",
        "    return sum(word_lengths) / len(word_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Yd8TnpLFvzH"
      },
      "outputs": [],
      "source": [
        "# Function to count punctuation marks in a sentence\n",
        "def count_punctuation(sentence):\n",
        "    punctuation_count = sum([1 for char in sentence if char in string.punctuation])\n",
        "    return punctuation_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRfXsKSBPvzB"
      },
      "outputs": [],
      "source": [
        "# Function to count stop words in each sentence\n",
        "def stopword_proportion(sentence):\n",
        "    words = sentence.split()\n",
        "    total_words = len(words)\n",
        "    stop_words_in_sentence = [word for word in words if word.lower() in stop_words]\n",
        "    num_stopwords = len(stop_words_in_sentence)\n",
        "    if total_words == 0:\n",
        "        return 0\n",
        "    return num_stopwords / total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIsKAOyoF1Ih"
      },
      "outputs": [],
      "source": [
        "# Function to get POS tags for each word in a sentence\n",
        "def get_pos_tags(sentence):\n",
        "    words = sentence.split()\n",
        "    pos_tags = pos_tag(words)\n",
        "    return pos_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-esz8wGF-zn"
      },
      "outputs": [],
      "source": [
        "# Function to calculate readability score of a sentence (Flesch-Kincaid)\n",
        "def flesch_kincaid_readability(sentence):\n",
        "    words = sentence.split()\n",
        "    num_words = len(words)\n",
        "    num_sentences = 1  # assuming each input is a single sentence\n",
        "    num_syllables = sum([syllable_count(word) for word in words])\n",
        "    readability = 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
        "    return readability\n",
        "\n",
        "# Function to count syllables in a word for readability score calculation\n",
        "def syllable_count(word):\n",
        "    count = 0\n",
        "    vowels = 'aeiouy'\n",
        "    word = word.lower()\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith('e'):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CedvNItqyEB3"
      },
      "outputs": [],
      "source": [
        "# Load the French language model\n",
        "import spacy\n",
        "nlp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "# Function to analyze parts of speech in a sentence\n",
        "def analyze_pos(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    pos_counts = {}\n",
        "    for token in doc:\n",
        "        if token.pos_ in pos_counts:\n",
        "            pos_counts[token.pos_] += 1\n",
        "        else:\n",
        "            pos_counts[token.pos_] = 1\n",
        "    return pos_counts\n",
        "\n",
        "## TRAINING DATA\n",
        "# Apply the function to each sentence\n",
        "training_data['pos_counts'] = training_data['sentence'].apply(analyze_pos)\n",
        "\n",
        "# Create columns for each part of speech count\n",
        "pos_set = set()\n",
        "training_data['pos_counts'].apply(lambda counts: pos_set.update(counts.keys()))\n",
        "for pos in pos_set:\n",
        "    training_data[pos] = training_data['pos_counts'].apply(lambda counts: counts.get(pos, 0))\n",
        "\n",
        "# Drop the temporary 'pos_counts' column\n",
        "training_data.drop(columns=['pos_counts'], inplace=True)\n",
        "\n",
        "\n",
        "## DATA PREDICTIONS\n",
        "# Apply the function to each sentence\n",
        "unlabelled_test_data['pos_counts'] = unlabelled_test_data['sentence'].apply(analyze_pos)\n",
        "\n",
        "# Create columns for each part of speech count\n",
        "pos_set = set()\n",
        "unlabelled_test_data['pos_counts'].apply(lambda counts: pos_set.update(counts.keys()))\n",
        "for pos in pos_set:\n",
        "    unlabelled_test_data[pos] = unlabelled_test_data['pos_counts'].apply(lambda counts: counts.get(pos, 0))\n",
        "\n",
        "\n",
        "# Drop the temporary 'pos_counts' column\n",
        "unlabelled_test_data.drop(columns=['pos_counts'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wSJ6NFYGD5V"
      },
      "outputs": [],
      "source": [
        "# Apply the functions to the DataFrame\n",
        "training_data['count_words'] = training_data['sentence'].apply(count_words)\n",
        "training_data['sentence'] = training_data['sentence'].apply(add_dot)\n",
        "training_data['avg_word_length'] = training_data['sentence'].apply(avg_word_length)\n",
        "training_data['punctuation_count'] = training_data['sentence'].apply(count_punctuation)\n",
        "training_data['stopword_proportion'] = training_data['sentence'].apply(stopword_proportion)\n",
        "training_data['flesch_kincaid_readability'] = training_data['sentence'].apply(flesch_kincaid_readability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w_EQeMfp-PLZ",
        "outputId": "ecee146e-ec69-434f-9074-8d8534147693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence difficulty  DET  \\\n",
              "0        0  Les coûts kilométriques réels peuvent diverger...         C1    3   \n",
              "1        1  Le bleu, c'est ma couleur préférée mais je n'a...         A1    3   \n",
              "2        2  Le test de niveau en français est sur le site ...         A1    3   \n",
              "3        3           Est-ce que ton mari est aussi de Boston?         A1    0   \n",
              "4        4  Dans les écoles de commerce, dans les couloirs...         B1    4   \n",
              "...    ...                                                ...        ...  ...   \n",
              "4795  4795  C'est pourquoi, il décida de remplacer les hab...         B2    4   \n",
              "4796  4796  Il avait une de ces pâleurs splendides qui don...         C1    3   \n",
              "4797  4797  Et le premier samedi de chaque mois, venez ren...         A2    3   \n",
              "4798  4798  Les coûts liés à la journalisation n'étant pas...         C2    7   \n",
              "4799  4799  Sur le sable, la mer haletait de toute la resp...         C2    4   \n",
              "\n",
              "      INTJ  PUNCT  PRON  ADP  PROPN  ADV  ...  CCONJ  X  VERB  NUM  ADJ  \\\n",
              "0        0      5     0   13      0    2  ...      1  0     4    0    3   \n",
              "1        0      2     2    0      1    2  ...      1  0     2    0    0   \n",
              "2        0      1     0    4      0    0  ...      0  0     1    0    0   \n",
              "3        0      1     1    1      1    1  ...      0  0     1    0    0   \n",
              "4        0      5     2   11      0    1  ...      1  0     4    2    2   \n",
              "...    ...    ...   ...  ...    ...  ...  ...    ... ..   ...  ...  ...   \n",
              "4795     0      3     4    4      0    2  ...      0  0     7    0    1   \n",
              "4796     0      1     3    5      0    0  ...      0  0     3    0    1   \n",
              "4797     0      2     0    2      0    0  ...      1  0     2    0    1   \n",
              "4798     0      2     0    3      0    4  ...      2  0     2    0    4   \n",
              "4799     0      2     1    3      0    1  ...      1  0     1    0    3   \n",
              "\n",
              "      count_words  avg_word_length  punctuation_count  stopword_proportion  \\\n",
              "0              38         5.736842                  8             0.394737   \n",
              "1              12         4.250000                  4             0.500000   \n",
              "2              13         4.153846                  2             0.538462   \n",
              "3               8         4.125000                  2             0.500000   \n",
              "4              34         5.176471                  9             0.411765   \n",
              "...           ...              ...                ...                  ...   \n",
              "4795           26         5.384615                  4             0.384615   \n",
              "4796           21         4.666667                  1             0.523810   \n",
              "4797           14         4.785714                  2             0.357143   \n",
              "4798           32         6.093750                  5             0.406250   \n",
              "4799           17         4.647059                  2             0.470588   \n",
              "\n",
              "      flesch_kincaid_readability  \n",
              "0                      14.649211  \n",
              "1                     103.005000  \n",
              "2                      76.501538  \n",
              "3                      82.390000  \n",
              "4                      40.448529  \n",
              "...                          ...  \n",
              "4795                   30.768077  \n",
              "4796                   60.634286  \n",
              "4797                   59.682143  \n",
              "4798                   26.305000  \n",
              "4799                   55.215294  \n",
              "\n",
              "[4800 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27b4074e-2a04-4223-b1c0-ac85bf0024aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>DET</th>\n",
              "      <th>INTJ</th>\n",
              "      <th>PUNCT</th>\n",
              "      <th>PRON</th>\n",
              "      <th>ADP</th>\n",
              "      <th>PROPN</th>\n",
              "      <th>ADV</th>\n",
              "      <th>...</th>\n",
              "      <th>CCONJ</th>\n",
              "      <th>X</th>\n",
              "      <th>VERB</th>\n",
              "      <th>NUM</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>count_words</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>stopword_proportion</th>\n",
              "      <th>flesch_kincaid_readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>38</td>\n",
              "      <td>5.736842</td>\n",
              "      <td>8</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>14.649211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>103.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>4.153846</td>\n",
              "      <td>2</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>76.501538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>82.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>5.176471</td>\n",
              "      <td>9</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>40.448529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>4795</td>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>5.384615</td>\n",
              "      <td>4</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>30.768077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>4796</td>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>60.634286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>4797</td>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>4.785714</td>\n",
              "      <td>2</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>59.682143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>4798</td>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>6.093750</td>\n",
              "      <td>5</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>26.305000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>4799</td>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>C2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>4.647059</td>\n",
              "      <td>2</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>55.215294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27b4074e-2a04-4223-b1c0-ac85bf0024aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27b4074e-2a04-4223-b1c0-ac85bf0024aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27b4074e-2a04-4223-b1c0-ac85bf0024aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd9fcb3e-949f-4d2a-853c-18e1318c32f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd9fcb3e-949f-4d2a-853c-18e1318c32f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd9fcb3e-949f-4d2a-853c-18e1318c32f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9bTy14tYT4H"
      },
      "outputs": [],
      "source": [
        "features = ['count_words', 'avg_word_length', 'punctuation_count', 'stopword_proportion',\n",
        "                   'flesch_kincaid_readability', 'ADV', 'SCONJ', 'NOUN', 'INTJ', 'DET', 'ADP',\n",
        "                   'PRON', 'X', 'ADJ', 'AUX', 'PROPN', 'CCONJ', 'VERB', 'NUM']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeLXfRtn36YV"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNwTFtZiW04w"
      },
      "source": [
        "## Only Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9EDVhhQfiAqU"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data['sentence']\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Create a pipeline that includes TF-IDF vectorization followed by logistic regression\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('classifier', LogisticRegression(max_iter=1000, random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "    'tfidf__use_idf': [True, False],\n",
        "    'classifier__C': [0.01, 0.1, 1, 10],\n",
        "    'classifier__penalty': ['l2', 'l1', 'none'],\n",
        "    'classifier__solver': ['liblinear', 'lbfgs']  # liblinear works with l1 penalty, lbfgs with l2 and none\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEe7ff1AicBX"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_LR_sentence = grid_search.best_estimator_\n",
        "y_pred = best_model_LR_sentence.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQG1XvPNidyz"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVfYDWu4W9YR"
      },
      "source": [
        "## Additional Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8v8c7i2daTW"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data[features + ['sentence']]\n",
        "y = training_data['difficulty']\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Define the column transformer to account for the sentences and additional features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf', TfidfVectorizer(), 'sentence'),\n",
        "        ('scaler', StandardScaler(), features)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', column_transformer),\n",
        "    ('classifier', LogisticRegression(max_iter=1000, random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'preprocessor__tfidf__use_idf': [True, False],\n",
        "    'classifier__C': [0.1, 1, 10],\n",
        "    'classifier__penalty': ['l2', 'none']\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=2, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whR7G8UjdfMA"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_LR_features = grid_search.best_estimator_\n",
        "y_pred = best_model_LR_features.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiTIryArhX00"
      },
      "outputs": [],
      "source": [
        "# Print detailed classification metrics\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfkNs52SHZ6r"
      },
      "source": [
        "## Additional features (no POS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KkMMSmxTaGO5"
      },
      "outputs": [],
      "source": [
        "features = ['count_words', 'avg_word_length', 'punctuation_count', 'stopword_proportion',\n",
        "                   'flesch_kincaid_readability']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kJZC0qs6HdRA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfb694bc-6d00-43db-ce15-864339240ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   1.0s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   1.6s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   2.0s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   1.9s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   2.2s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   1.6s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   4.6s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   5.3s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   3.9s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   4.3s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   4.7s\n",
            "[CV] END classifier__C=0.1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   8.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=0.1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   8.0s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   3.0s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   3.7s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   3.8s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   3.7s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   3.4s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   2.7s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  12.0s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  12.1s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  11.2s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  11.5s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  11.4s\n",
            "[CV] END classifier__C=1, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  10.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   5.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   8.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=1, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   7.9s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   7.7s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   6.0s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   9.1s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=  10.4s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   9.2s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   7.8s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  21.8s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  23.5s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=  19.3s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  26.8s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  27.0s\n",
            "[CV] END classifier__C=10, classifier__penalty=l2, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  27.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   5.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=True; total time=   3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 1), preprocessor__tfidf__use_idf=False; total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   8.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=True; total time=   7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=  13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END classifier__C=10, classifier__penalty=none, preprocessor__tfidf__ngram_range=(1, 2), preprocessor__tfidf__use_idf=False; total time=   7.8s\n",
            "Best parameters found:  {'classifier__C': 10, 'classifier__penalty': 'l2', 'preprocessor__tfidf__ngram_range': (1, 2), 'preprocessor__tfidf__use_idf': True}\n",
            "Best cross-validation accuracy:  0.47109375000000003\n",
            "Test Accuracy with best model:  0.49895833333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.73      0.64       153\n",
            "           1       0.48      0.44      0.46       156\n",
            "           2       0.44      0.49      0.46       153\n",
            "           3       0.48      0.50      0.49       173\n",
            "           4       0.44      0.31      0.37       166\n",
            "           5       0.57      0.54      0.56       159\n",
            "\n",
            "    accuracy                           0.50       960\n",
            "   macro avg       0.50      0.50      0.49       960\n",
            "weighted avg       0.49      0.50      0.49       960\n",
            "\n",
            "Model saved as 'best_model_LR_features.joblib'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c39c3ccd-7eb3-4ba1-82cf-4078ec5637dc\", \"best_model_LR_features.joblib\", 4639718)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data[features + ['sentence']]\n",
        "y = training_data['difficulty']\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Define the column transformer to account for the sentences and additional features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf', TfidfVectorizer(), 'sentence'),\n",
        "        ('scaler', StandardScaler(), features)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', column_transformer),\n",
        "    ('classifier', LogisticRegression(max_iter=1000, random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'preprocessor__tfidf__use_idf': [True, False],\n",
        "    'classifier__C': [0.1, 1, 10],\n",
        "    'classifier__penalty': ['l2', 'none']\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_LR_features = grid_search.best_estimator_\n",
        "y_pred = best_model_LR_features.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)\n",
        "\n",
        "# Print detailed classification metrics\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(best_model_LR_features, 'best_model_LR_features.joblib')\n",
        "print(\"Model saved as 'best_model_LR_features.joblib'\")\n",
        "\n",
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save the model to Colab's local file system\n",
        "model_filename = 'best_model_LR_features.joblib'\n",
        "joblib.dump(best_model_LR_features, model_filename)\n",
        "\n",
        "# Trigger a browser download\n",
        "files.download(model_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvmrBZPN32ir"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR0dg3husWwz"
      },
      "source": [
        "## Only Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G24tbKqLsa-G"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data['sentence']\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Create a pipeline that includes TF-IDF vectorization followed by RandomForestClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('classifier', RandomForestClassifier(random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': [True, False],\n",
        "    'classifier__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'classifier__max_depth': [None, 10, 20, 30],  # Maximum number of levels in each decision tree\n",
        "    'classifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]     # Minimum number of samples required at each leaf node\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIFrEVRkyj12"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=2, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_RF_sentence = grid_search.best_estimator_\n",
        "y_pred = best_model_RF_sentence.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH-jOJXos2YB"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A0fHaVL1SFA"
      },
      "source": [
        "## Additional Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FteeiYIs1clF"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data[features + ['sentence']]\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Define the column transformer to account for the sentences and the additional features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf', TfidfVectorizer(), 'sentence'),  # Apply TF-IDF to the 'sentence' column\n",
        "        ('scaler', StandardScaler(), features)     # Apply scaling to features columns\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "# Define the pipeline with Random Forest as the classifier\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', column_transformer),\n",
        "    ('classifier', RandomForestClassifier(random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Define the parameter grid for Random Forest and TF-IDF\n",
        "param_grid = {\n",
        "    'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'preprocessor__tfidf__use_idf': [True, False],\n",
        "    'classifier__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'classifier__max_depth': [None, 10, 20, 30],  # Maximum number of levels in each decision tree\n",
        "    'classifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]    # Minimum number of samples required at each leaf node\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL0wQPWW2bBP"
      },
      "outputs": [],
      "source": [
        "# Setup GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_RF_features = grid_search.best_estimator_\n",
        "y_pred = best_model_RF_features.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZGOhNRM2czu"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbH-M60b3y8W"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0yiFQKL5Kel"
      },
      "source": [
        "## Only Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-Fvsl8f5QnN"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data['sentence']\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Create a pipeline that includes TF-IDF vectorization followed by Decision Tree classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Define the parameter grid to search for Decision Tree\n",
        "param_grid = {\n",
        "    'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'preprocessor__tfidf__use_idf': [True, False],\n",
        "    'classifier__max_depth': [None, 10, 20, 30],  # Maximum number of levels in each decision tree\n",
        "    'classifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP2NN8AV6VqH"
      },
      "outputs": [],
      "source": [
        "# Setup GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_DT_sentence = grid_search.best_estimator_\n",
        "y_pred = best_model_DT_sentence.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-flIxNQ6fi7"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crl27jPn5MVH"
      },
      "source": [
        "## Additional Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x02ORMbk6q6C"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data[features + ['sentence']]\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Define the column transformer to account for the sentences and the additional features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf', TfidfVectorizer(), 'sentence'),\n",
        "        ('scaler', StandardScaler(), features)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "# Update the pipeline with a Decision Tree classifier\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', column_transformer),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=random_seed))\n",
        "])\n",
        "\n",
        "# Update the parameter grid for the Decision Tree\n",
        "param_grid = {\n",
        "    'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'preprocessor__tfidf__use_idf': [True, False],\n",
        "    'classifier__max_depth': [None, 10, 20, 30],  # Control over-fitting by limiting the depth of trees\n",
        "    'classifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]    # Minimum number of samples required to be at a leaf node\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zssdnq2U7pbR"
      },
      "outputs": [],
      "source": [
        "# Setup GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_DT_features = grid_search.best_estimator_\n",
        "y_pred = best_model_DT_features.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wELTbwDq7sCs"
      },
      "outputs": [],
      "source": [
        "# Print detailed classification metrics\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdxq0yZT3vcz"
      },
      "source": [
        "# KNN Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjoENCsE8jrP"
      },
      "source": [
        "## Only Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwgHqgXVTyGd"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data['sentence']\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Create a pipeline that includes TF-IDF vectorization followed by KNN classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('classifier', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Define the parameter grid to search for KNN\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': [True, False],\n",
        "    'classifier__n_neighbors': [3, 5, 6, 7],  # Number of neighbors to use\n",
        "    'classifier__weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
        "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithm used to compute the nearest neighbors\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ48Zugi9Djx"
      },
      "outputs": [],
      "source": [
        "# Setup GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_KNN_sentence = grid_search.best_estimator_\n",
        "y_pred = best_model_KNN_sentence.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_MfefrN9LBl"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ID-o-m9QlT"
      },
      "source": [
        "## Additional Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpbB2ENQ9TyA"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "\n",
        "# Define X and y\n",
        "X = training_data[features + ['sentence']]\n",
        "y = training_data['difficulty']\n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Define the column transformer for handling sentences and additional features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf', TfidfVectorizer(), 'sentence'),\n",
        "        ('scaler', StandardScaler(), features)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "# Update the pipeline with a KNN classifier\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', column_transformer),\n",
        "    ('classifier', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Update the parameter grid for KNN\n",
        "param_grid = {\n",
        "    'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'preprocessor__tfidf__use_idf': [True, False],\n",
        "    'classifier__n_neighbors': [3, 5, 6, 7],  # Number of neighbors\n",
        "    'classifier__weights': ['uniform', 'distance'],  # Weighting type\n",
        "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithm to compute nearest neighbors\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbFCvr3N986r"
      },
      "outputs": [],
      "source": [
        "# Setup GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Test the best model on the test data\n",
        "best_model_KNN_features = grid_search.best_estimator_\n",
        "y_pred = best_model_KNN_features.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with best model: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeSZFLrY-BZu"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZxaI-Sf3qaR"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RUbMDyZfN3l"
      },
      "source": [
        "## One Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iEdKY1NTqA8"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "y = training_data['difficulty']\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(training_data['sentence']).toarray()\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale X features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert scaled X_train and X_test to torch tensors of type torch.float\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
        "\n",
        "# Convert y_train and y_test to torch tensors of type torch.long\n",
        "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTFTBlrh4Aw0"
      },
      "outputs": [],
      "source": [
        "# Define the neural network class\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, D_in, H1, D_out):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, D_out)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = self.activation(self.linear1(x))\n",
        "        y_pred = self.linear2(y_pred)\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K56a76BL4PLg"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "iterations = [500, 1000, 1500]\n",
        "learning_rates = [0.001, 1.049, 12.031]\n",
        "\n",
        "# Input and output sizes\n",
        "D_in = X_train_tensor.shape[1]\n",
        "D_out = len(label_encoder.classes_)\n",
        "\n",
        "# Accuracy Initialization\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "# Training and evaluation of the model\n",
        "for iteration in iterations:\n",
        "    for lr in learning_rates:\n",
        "        model = NeuralNetwork(D_in, 150, D_out)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Training loop\n",
        "        for i in range(iteration):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_train_tensor)\n",
        "            loss = criterion(y_pred, y_train_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            outputs = model(X_test_tensor)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y_test_tensor.size(0)\n",
        "            correct += (predicted == y_test_tensor).sum().item()\n",
        "\n",
        "        # Print accuracy\n",
        "        accuracy = correct*100 / total\n",
        "        print(f\"Iterations: {iteration}, Learning Rate: {lr}, Accuracy: {accuracy}%\")\n",
        "\n",
        "        # Save the best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "# Save the best model\n",
        "torch.save(best_model.state_dict(), 'best_model.pth')\n",
        "print(\"Best model saved with accuracy:\", best_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi9z_6QoDveo"
      },
      "outputs": [],
      "source": [
        "# Convert class labels to string if necessary\n",
        "class_names = [str(cls) for cls in label_encoder.classes_]\n",
        "\n",
        "# Ensure the best model is in evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    outputs = best_model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Convert predictions and true labels to CPU numpy arrays if running on a GPU\n",
        "predicted = predicted.cpu().numpy()\n",
        "y_true = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true, predicted, target_names=class_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYgQ3IGd309k"
      },
      "source": [
        "## Additional Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpqVjpgu33j5"
      },
      "outputs": [],
      "source": [
        "# Encode the 'difficulty' label\n",
        "label_encoder = LabelEncoder()\n",
        "training_data[\"difficulty\"] = label_encoder.fit_transform(training_data[\"difficulty\"])\n",
        "y = training_data['difficulty'].values\n",
        "\n",
        "# Define column transformer accounting for sentences and additional features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf', TfidfVectorizer(), 'sentence'),\n",
        "        ('scaler', StandardScaler(), features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Prepare X by fitting and transforming the data\n",
        "X = column_transformer.fit_transform(training_data[features + ['sentence']])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# Convert sparse matrix to dense\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Convert arrays to tensors\n",
        "X_train_tensor = torch.tensor(X_train_dense, dtype=torch.float)\n",
        "X_test_tensor = torch.tensor(X_test_dense, dtype=torch.float)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXBKiiR37yJ0"
      },
      "outputs": [],
      "source": [
        "# Neural network definition\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, D_in, H1, D_out):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(H1, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcM72kvB7lli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed96223-067e-4166-c6bc-73b60170af65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterations: 500, Learning Rate: 0.001, Accuracy: 18.854166666666668%\n",
            "Iterations: 500, Learning Rate: 1.049, Accuracy: 43.125%\n",
            "Iterations: 500, Learning Rate: 12.031, Accuracy: 15.833333333333334%\n",
            "Iterations: 1000, Learning Rate: 0.001, Accuracy: 30.833333333333332%\n",
            "Iterations: 1000, Learning Rate: 1.049, Accuracy: 44.270833333333336%\n",
            "Iterations: 1000, Learning Rate: 12.031, Accuracy: 16.666666666666668%\n",
            "Iterations: 1500, Learning Rate: 0.001, Accuracy: 28.541666666666668%\n",
            "Iterations: 1500, Learning Rate: 1.049, Accuracy: 50.104166666666664%\n",
            "Iterations: 1500, Learning Rate: 12.031, Accuracy: 16.041666666666668%\n",
            "Best model saved with accuracy: 50.104166666666664\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "iterations = [500, 1000, 1500]\n",
        "learning_rates = [0.001, 1.049, 12.031]\n",
        "\n",
        "# Input and output sizes\n",
        "D_in = X_train_tensor.shape[1]  # Correct number of input features\n",
        "D_out = len(label_encoder.classes_)  # Number of classes\n",
        "\n",
        "# Accuracy Initialization\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "# Training and evaluation of the model\n",
        "for iteration in iterations:\n",
        "    for lr in learning_rates:\n",
        "        model = NeuralNetwork(D_in, 150, D_out)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Training loop\n",
        "        for i in range(iteration):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_train_tensor)\n",
        "            loss = criterion(y_pred, y_train_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            outputs = model(X_test_tensor)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y_test_tensor.size(0)\n",
        "            correct += (predicted == y_test_tensor).sum().item()\n",
        "            accuracy = correct * 100 / total\n",
        "\n",
        "        print(f\"Iterations: {iteration}, Learning Rate: {lr}, Accuracy: {accuracy}%\")\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "# Save the best model\n",
        "torch.save(best_model.state_dict(), 'best_model.pth')\n",
        "print(\"Best model saved with accuracy:\", best_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehx2KWWA_LxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28ed6a0-f4cc-4501-9983-71bb0bb5fc2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.36      0.49       153\n",
            "           1       0.43      0.78      0.56       156\n",
            "           2       0.56      0.45      0.50       153\n",
            "           3       0.50      0.49      0.49       173\n",
            "           4       0.42      0.58      0.49       166\n",
            "           5       0.64      0.34      0.44       159\n",
            "\n",
            "    accuracy                           0.50       960\n",
            "   macro avg       0.55      0.50      0.50       960\n",
            "weighted avg       0.55      0.50      0.49       960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert class labels to string if necessary\n",
        "class_names = [str(cls) for cls in label_encoder.classes_]\n",
        "\n",
        "# Ensure the best model is in evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    outputs = best_model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Convert predictions and true labels to CPU numpy arrays if running on a GPU\n",
        "predicted = predicted.cpu().numpy()\n",
        "y_true = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true, predicted, target_names=class_names)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}